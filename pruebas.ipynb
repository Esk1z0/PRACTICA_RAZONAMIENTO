{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f55e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.4.0\n",
      "\u001b[2K    Uninstalling numpy-2.4.0:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.4.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [opencv-python]0m [opencv-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy import ndimage\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TopologicalGraphExtractor:\n",
    "    def __init__(self, map_path, resolution=0.05, occupied_thresh=65, free_thresh=25):\n",
    "        \"\"\"\n",
    "        Extractor de grafo topológico desde PGM (formato ROS)\n",
    "        \n",
    "        Args:\n",
    "            map_path: ruta al archivo PGM del mapa\n",
    "            resolution: resolución del mapa en metros/píxel\n",
    "            occupied_thresh: umbral para considerar celda ocupada (>= este valor)\n",
    "            free_thresh: umbral para considerar celda libre (<= este valor)\n",
    "        \"\"\"\n",
    "        self.map_path = map_path\n",
    "        self.resolution = resolution\n",
    "        \n",
    "        # Leer PGM (formato nativo de ROS)\n",
    "        self.img = cv2.imread(map_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if self.img is None:\n",
    "            raise ValueError(f\"No se pudo cargar la imagen en {map_path}\")\n",
    "        \n",
    "        # En PGM de ROS: 254=libre, 0=ocupado, 205=desconocido\n",
    "        # Convertir a binario: 255=libre, 0=ocupado\n",
    "        self.binary = np.zeros_like(self.img)\n",
    "        self.binary[self.img >= 254 - free_thresh] = 255  # Libre\n",
    "        self.binary[self.img <= occupied_thresh] = 0       # Ocupado\n",
    "        # Desconocido se trata como ocupado por defecto\n",
    "        \n",
    "    def method_voronoi(self, visualize=False):\n",
    "        \"\"\"\n",
    "        Método 1: Diagrama de Voronoi (el más rápido y eficiente)\n",
    "        Extrae el esqueleto topológico del espacio libre\n",
    "        \"\"\"\n",
    "        # Distancia transform\n",
    "        dist = cv2.distanceTransform(self.binary, cv2.DIST_L2, 5)\n",
    "        \n",
    "        # Esqueleto usando thinning de Zhang-Suen\n",
    "        skeleton = cv2.ximgproc.thinning(self.binary)\n",
    "        \n",
    "        # Solo quedarnos con puntos que están suficientemente lejos de obstáculos\n",
    "        threshold_dist = 3  # píxeles mínimos de distancia\n",
    "        skeleton_filtered = np.logical_and(skeleton > 0, dist > threshold_dist).astype(np.uint8) * 255\n",
    "        \n",
    "        # Encontrar nodos (puntos de intersección y extremos)\n",
    "        nodes = self._find_junction_points(skeleton_filtered)\n",
    "        \n",
    "        # Construir grafo\n",
    "        G = self._skeleton_to_graph(skeleton_filtered, nodes)\n",
    "        \n",
    "        if visualize:\n",
    "            self._visualize_graph(G, skeleton_filtered, \"Método Voronoi\")\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def method_room_segmentation(self, visualize=False):\n",
    "        \"\"\"\n",
    "        Método 2: Segmentación de habitaciones (más semántico)\n",
    "        Identifica habitaciones y sus conexiones\n",
    "        \"\"\"\n",
    "        # Cerrar puertas con morfología\n",
    "        kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "        closed = cv2.morphologyEx(self.binary, cv2.MORPH_CLOSE, kernel_close)\n",
    "        \n",
    "        # Abrir para limpiar ruido\n",
    "        kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open)\n",
    "        \n",
    "        # Segmentar en componentes conectados\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(opened, connectivity=8)\n",
    "        \n",
    "        # Filtrar habitaciones por tamaño mínimo\n",
    "        min_area = 500  # píxeles\n",
    "        rooms = []\n",
    "        for i in range(1, num_labels):  # Skip background (0)\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            if area > min_area:\n",
    "                rooms.append({\n",
    "                    'id': len(rooms),\n",
    "                    'label': i,\n",
    "                    'centroid': centroids[i],\n",
    "                    'area': area,\n",
    "                    'bbox': stats[i][:4]  # x, y, w, h\n",
    "                })\n",
    "        \n",
    "        # Construir grafo de habitaciones\n",
    "        G = nx.Graph()\n",
    "        for room in rooms:\n",
    "            G.add_node(room['id'], \n",
    "                      pos=room['centroid'],\n",
    "                      area=room['area'] * (self.resolution ** 2))\n",
    "        \n",
    "        # Detectar conexiones entre habitaciones\n",
    "        self._detect_room_connections(G, rooms, labels)\n",
    "        \n",
    "        if visualize:\n",
    "            self._visualize_room_graph(G, rooms, labels)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def method_critical_points(self, visualize=False):\n",
    "        \"\"\"\n",
    "        Método 3: Puntos críticos con DBSCAN (híbrido, balance velocidad/calidad)\n",
    "        Combina esqueleto con clustering de puntos importantes\n",
    "        \"\"\"\n",
    "        # Distance transform\n",
    "        dist = cv2.distanceTransform(self.binary, cv2.DIST_L2, 5)\n",
    "        \n",
    "        # Encontrar puntos con alta distancia (centros de pasillos/habitaciones)\n",
    "        _, critical = cv2.threshold(dist, dist.max() * 0.4, 255, cv2.THRESH_BINARY)\n",
    "        critical = critical.astype(np.uint8)\n",
    "        \n",
    "        # Extraer coordenadas de puntos críticos\n",
    "        points = np.column_stack(np.where(critical > 0))\n",
    "        \n",
    "        if len(points) < 2:\n",
    "            return nx.Graph()\n",
    "        \n",
    "        # Clustering con DBSCAN\n",
    "        clustering = DBSCAN(eps=20, min_samples=5).fit(points)\n",
    "        \n",
    "        # Calcular centroides de clusters\n",
    "        G = nx.Graph()\n",
    "        unique_labels = set(clustering.labels_) - {-1}  # Ignorar ruido\n",
    "        \n",
    "        centroids = []\n",
    "        for label in unique_labels:\n",
    "            cluster_points = points[clustering.labels_ == label]\n",
    "            centroid = cluster_points.mean(axis=0)\n",
    "            centroids.append(centroid)\n",
    "            G.add_node(len(centroids) - 1, pos=(centroid[1], centroid[0]))\n",
    "        \n",
    "        # Conectar nodos cercanos que tengan línea de vista libre\n",
    "        for i, c1 in enumerate(centroids):\n",
    "            for j, c2 in enumerate(centroids[i+1:], start=i+1):\n",
    "                if self._has_line_of_sight(c1, c2):\n",
    "                    dist_euclidean = np.linalg.norm(c1 - c2) * self.resolution\n",
    "                    G.add_edge(i, j, weight=dist_euclidean)\n",
    "        \n",
    "        if visualize:\n",
    "            self._visualize_graph(G, self.binary, \"Método Puntos Críticos\")\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def _find_junction_points(self, skeleton):\n",
    "        \"\"\"Encuentra puntos de intersección en el esqueleto\"\"\"\n",
    "        # Kernel para detectar intersecciones\n",
    "        kernel = np.array([[1, 1, 1],\n",
    "                          [1, 10, 1],\n",
    "                          [1, 1, 1]], dtype=np.uint8)\n",
    "        \n",
    "        filtered = cv2.filter2D(skeleton // 255, -1, kernel)\n",
    "        \n",
    "        # Nodos: puntos con 3+ vecinos (intersecciones) o 1 vecino (extremos)\n",
    "        junctions = np.where(np.logical_or(filtered >= 13, \n",
    "                                          np.logical_and(filtered >= 11, filtered <= 12)))\n",
    "        return list(zip(junctions[1], junctions[0]))  # (x, y)\n",
    "    \n",
    "    def _skeleton_to_graph(self, skeleton, nodes, max_nodes=50):\n",
    "        \"\"\"Convierte esqueleto y nodos en grafo\"\"\"\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Limitar número de nodos si hay demasiados\n",
    "        if len(nodes) > max_nodes:\n",
    "            # Submuestrear uniformemente\n",
    "            step = len(nodes) // max_nodes\n",
    "            nodes = nodes[::step]\n",
    "        \n",
    "        # Añadir nodos\n",
    "        for i, (x, y) in enumerate(nodes):\n",
    "            G.add_node(i, pos=(x, y))\n",
    "        \n",
    "        # Conectar nodos cercanos con línea de vista\n",
    "        for i, n1 in enumerate(nodes):\n",
    "            for j, n2 in enumerate(nodes[i+1:], start=i+1):\n",
    "                dist = np.linalg.norm(np.array(n1) - np.array(n2))\n",
    "                if dist < 100 and self._has_line_of_sight_pixels(n1, n2):\n",
    "                    G.add_edge(i, j, weight=dist * self.resolution)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def _detect_room_connections(self, G, rooms, labels):\n",
    "        \"\"\"Detecta puertas/conexiones entre habitaciones\"\"\"\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        \n",
    "        for i, room1 in enumerate(rooms):\n",
    "            mask1 = (labels == room1['label']).astype(np.uint8)\n",
    "            dilated1 = cv2.dilate(mask1, kernel)\n",
    "            \n",
    "            for j, room2 in enumerate(rooms[i+1:], start=i+1):\n",
    "                mask2 = (labels == room2['label']).astype(np.uint8)\n",
    "                dilated2 = cv2.dilate(mask2, kernel)\n",
    "                \n",
    "                # Intersección de máscaras dilatadas = puerta\n",
    "                overlap = np.logical_and(dilated1, dilated2)\n",
    "                \n",
    "                if np.sum(overlap) > 10:  # Threshold de conexión\n",
    "                    # Calcular distancia euclidiana entre centroides\n",
    "                    c1 = np.array(room1['centroid'])\n",
    "                    c2 = np.array(room2['centroid'])\n",
    "                    dist = np.linalg.norm(c1 - c2) * self.resolution\n",
    "                    G.add_edge(room1['id'], room2['id'], weight=dist)\n",
    "    \n",
    "    def _has_line_of_sight(self, p1, p2):\n",
    "        \"\"\"Verifica si hay línea de vista entre dos puntos (coordenadas array)\"\"\"\n",
    "        p1 = (int(p1[1]), int(p1[0]))  # (x, y)\n",
    "        p2 = (int(p2[1]), int(p2[0]))\n",
    "        return self._has_line_of_sight_pixels(p1, p2)\n",
    "    \n",
    "    def _has_line_of_sight_pixels(self, p1, p2):\n",
    "        \"\"\"Verifica línea de vista entre puntos en coordenadas de píxeles\"\"\"\n",
    "        # Bresenham's line algorithm\n",
    "        x1, y1 = p1\n",
    "        x2, y2 = p2\n",
    "        \n",
    "        points = []\n",
    "        dx = abs(x2 - x1)\n",
    "        dy = abs(y2 - y1)\n",
    "        sx = 1 if x1 < x2 else -1\n",
    "        sy = 1 if y1 < y2 else -1\n",
    "        err = dx - dy\n",
    "        \n",
    "        x, y = x1, y1\n",
    "        while True:\n",
    "            if 0 <= x < self.binary.shape[1] and 0 <= y < self.binary.shape[0]:\n",
    "                if self.binary[y, x] == 0:  # Obstáculo\n",
    "                    return False\n",
    "            \n",
    "            if x == x2 and y == y2:\n",
    "                break\n",
    "            \n",
    "            e2 = 2 * err\n",
    "            if e2 > -dy:\n",
    "                err -= dy\n",
    "                x += sx\n",
    "            if e2 < dx:\n",
    "                err += dx\n",
    "                y += sy\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _visualize_graph(self, G, background, title):\n",
    "        \"\"\"Visualiza el grafo sobre el mapa\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        ax.imshow(background, cmap='gray')\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "        \n",
    "        # Dibujar aristas\n",
    "        for edge in G.edges():\n",
    "            p1 = pos[edge[0]]\n",
    "            p2 = pos[edge[1]]\n",
    "            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], 'b-', linewidth=2, alpha=0.6)\n",
    "        \n",
    "        # Dibujar nodos\n",
    "        for node, (x, y) in pos.items():\n",
    "            ax.plot(x, y, 'ro', markersize=8)\n",
    "            ax.text(x, y, str(node), color='white', fontsize=10, \n",
    "                   ha='center', va='center', weight='bold')\n",
    "        \n",
    "        ax.set_title(f\"{title} - {G.number_of_nodes()} nodos, {G.number_of_edges()} aristas\")\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _visualize_room_graph(self, G, rooms, labels):\n",
    "        \"\"\"Visualiza grafo de habitaciones\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        # Colorear habitaciones\n",
    "        colored = np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(rooms)))\n",
    "        \n",
    "        for i, room in enumerate(rooms):\n",
    "            mask = labels == room['label']\n",
    "            colored[mask] = (colors[i][:3] * 255).astype(np.uint8)\n",
    "        \n",
    "        ax.imshow(colored)\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "        \n",
    "        # Dibujar conexiones\n",
    "        for edge in G.edges():\n",
    "            p1 = pos[edge[0]]\n",
    "            p2 = pos[edge[1]]\n",
    "            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], 'k-', linewidth=3, alpha=0.7)\n",
    "        \n",
    "        # Dibujar centroides\n",
    "        for node, (x, y) in pos.items():\n",
    "            ax.plot(x, y, 'wo', markersize=12, markeredgecolor='black', markeredgewidth=2)\n",
    "            ax.text(x, y, str(node), color='black', fontsize=12, \n",
    "                   ha='center', va='center', weight='bold')\n",
    "        \n",
    "        ax.set_title(f\"Grafo de Habitaciones - {G.number_of_nodes()} habitaciones\")\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def export_to_text(self, G, method_name=\"\"):\n",
    "        \"\"\"Exporta el grafo a formato texto para LLM\"\"\"\n",
    "        output = f\"=== Grafo Topológico ({method_name}) ===\\n\\n\"\n",
    "        output += f\"Nodos: {G.number_of_nodes()}\\n\"\n",
    "        output += f\"Aristas: {G.number_of_edges()}\\n\\n\"\n",
    "        \n",
    "        output += \"Nodos:\\n\"\n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "        for node in G.nodes():\n",
    "            x, y = pos.get(node, (0, 0))\n",
    "            # Convertir a coordenadas del mundo\n",
    "            world_x = x * self.resolution\n",
    "            world_y = y * self.resolution\n",
    "            neighbors = list(G.neighbors(node))\n",
    "            output += f\"  Nodo {node}: pos=({world_x:.2f}, {world_y:.2f})m, vecinos={neighbors}\\n\"\n",
    "        \n",
    "        output += \"\\nConexiones:\\n\"\n",
    "        for edge in G.edges(data=True):\n",
    "            weight = edge[2].get('weight', 0)\n",
    "            output += f\"  {edge[0]} <-> {edge[1]}: distancia={weight:.2f}m\\n\"\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3876581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker-compose.yml  guia_utilizacion.md  \u001b[0m\u001b[01;34mmaps\u001b[0m/          README.md\n",
      "Dockerfile          mapa_practica2.ttt   pruebas.ipynb  \u001b[01;34msrc\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c124d443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analizando mapa PGM ===\n",
      "Dimensiones: (103, 201)\n",
      "Rango valores: 0-254\n",
      "Espacio libre: 11236 píxeles\n",
      "Espacio ocupado: 9467 píxeles\n",
      "\n",
      "Extrayendo grafo de habitaciones...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Grafo Topológico (Habitaciones) ===\n",
      "\n",
      "Nodos: 1\n",
      "Aristas: 0\n",
      "\n",
      "Nodos:\n",
      "  Nodo 0: pos=(4.73, 2.96)m, vecinos=[]\n",
      "\n",
      "Conexiones:\n",
      "\n",
      "\n",
      "Grafo guardado en 'grafo_mapa.pkl'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m data = json_graph.node_link_data(G)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mgrafo_mapa.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGrafo guardado en \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgrafo_mapa.json\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Opción 3: GraphML (estándar XML, compatible con otros tools)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/__init__.py:181\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    175\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    176\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    177\u001b[39m         separators=separators,\n\u001b[32m    178\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:435\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:409\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    407\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    408\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first \u001b[38;5;129;01mand\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    411\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:328\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_list\u001b[39m\u001b[34m(lst, _current_indent_level)\u001b[39m\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    327\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    330\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:409\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    407\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    408\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first \u001b[38;5;129;01mand\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    411\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:442\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    441\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/json/encoder.py:182\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    164\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m \n\u001b[32m    181\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    183\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Crear extractor para mapa PGM de ROS\n",
    "# El archivo YAML de ROS tiene la resolución, léelo o pásala manualmente\n",
    "extractor = TopologicalGraphExtractor(\n",
    "    \"./maps/mapa_practica3.pgm\", \n",
    "    resolution=0.05,  # Lee esto del YAML\n",
    "    occupied_thresh=0.65,  # Ajusta según tu mapa\n",
    "    free_thresh=0.25\n",
    ")\n",
    "\n",
    "\n",
    "print(\"=== Analizando mapa PGM ===\")\n",
    "print(f\"Dimensiones: {extractor.img.shape}\")\n",
    "print(f\"Rango valores: {extractor.img.min()}-{extractor.img.max()}\")\n",
    "print(f\"Espacio libre: {np.sum(extractor.binary == 255)} píxeles\")\n",
    "print(f\"Espacio ocupado: {np.sum(extractor.binary == 0)} píxeles\\n\")\n",
    "\n",
    "# Método recomendado para ROS: Habitaciones\n",
    "print(\"Extrayendo grafo de habitaciones...\")\n",
    "G = extractor.method_room_segmentation(visualize=True)\n",
    "\n",
    "# Exportar para LLM\n",
    "texto_llm = extractor.export_to_text(G, \"Habitaciones\")\n",
    "print(texto_llm)\n",
    "\n",
    "# Guardar grafo (varias opciones)\n",
    "\n",
    "# Opción 1: Pickle estándar (recomendado)\n",
    "import pickle\n",
    "with open(\"grafo_mapa.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G, f)\n",
    "print(\"\\nGrafo guardado en 'grafo_mapa.pkl'\")\n",
    "\n",
    "# Opción 2: JSON (más portable, legible)\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "data = json_graph.node_link_data(G)\n",
    "with open(\"grafo_mapa.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "print(\"Grafo guardado en 'grafo_mapa.json'\")\n",
    "\n",
    "# Opción 3: GraphML (estándar XML, compatible con otros tools)\n",
    "nx.write_graphml(G, \"grafo_mapa.graphml\")\n",
    "print(\"Grafo guardado en 'grafo_mapa.graphml'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b571af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.26.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in ./.venv/lib/python3.13/site-packages (from scikit-image) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.11.4 in ./.venv/lib/python3.13/site-packages (from scikit-image) (1.16.3)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.13/site-packages (from scikit-image) (3.6.1)\n",
      "Requirement already satisfied: pillow>=10.1 in ./.venv/lib/python3.13/site-packages (from scikit-image) (12.0.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.12.20-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.13/site-packages (from scikit-image) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.26.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2025.12.20-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-image][0m [scikit-image]\n",
      "\u001b[1A\u001b[2KSuccessfully installed imageio-2.37.2 lazy-loader-0.4 scikit-image-0.26.0 tifffile-2025.12.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21494f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.json          mapa_practica2.yaml  map.pgm       rosgraph.svg\n",
      "llm_current.json    mapa_practica3.pgm   map.yaml      \u001b[0m\u001b[01;32mwatch_llm.sh\u001b[0m*\n",
      "mapa_practica2.pgm  mapa_practica3.yaml  rosgraph.png\n"
     ]
    }
   ],
   "source": [
    "ls maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5645b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "# 1) Cargar PGM (OpenCV lo lee como grayscale)\n",
    "img = cv2.imread(\"./maps/mapa_practica2.pgm\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 2) Binarizar\n",
    "# Convención típica de mapas ROS en PGM: negro = obstáculo, blanco = libre (gris = unknown en algunos mapas)\n",
    "# Ajusta el umbral según tu PGM\n",
    "free = img > 200          # libre\n",
    "obst = img < 50           # obstáculo\n",
    "\n",
    "# Si tienes unknown (gris), decide: tratarlo como obstáculo para ser conservador\n",
    "unknown = (~free) & (~obst)\n",
    "obstacles = obst | unknown\n",
    "\n",
    "free_mask = (~obstacles).astype(np.uint8) * 255  # no-cero=free, cero=obstacle\n",
    "\n",
    "# 3) Distance transform (distancia al obstáculo más cercano)\n",
    "dist = cv2.distanceTransform(free_mask, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "\n",
    "# 4) Esqueleto (proxy GVD)\n",
    "skel = skeletonize(free_mask.astype(bool))\n",
    "\n",
    "# 5) Exportar un overlay simple\n",
    "gvd_img = np.zeros_like(img, dtype=np.uint8)\n",
    "gvd_img[skel] = 255\n",
    "cv2.imwrite(\"gvd_skeleton.pgm\", gvd_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
